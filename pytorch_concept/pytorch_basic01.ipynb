{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_basic01.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-F5Vqb2lS4SA"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import torch\n",
        "import math\n",
        "dtype = torch.float\n",
        "device = torch.device(\"cpu\")\n",
        "# device = torch.device(\"cuda:0\") # Gpu environment"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setting input, out put data randomly\n",
        "x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
        "y = torch.sin(x)"
      ],
      "metadata": {
        "id": "SJASPmLmTN2t"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x   ## tensor format"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdIQfn8XTjAb",
        "outputId": "5d6f33e5-1d06-4557-809a-adfc143cf9b0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-3.1416, -3.1384, -3.1353,  ...,  3.1353,  3.1384,  3.1416])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y  ## tensor format"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srnsqzBYTkqv",
        "outputId": "638ad5b2-ab89-42c1-d0ae-815e7983f3fe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 8.7423e-08, -3.1430e-03, -6.2863e-03,  ...,  6.2863e-03,\n",
              "         3.1432e-03, -8.7423e-08])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initiate the weight randomly\n",
        "a = torch.randn((), device=device, dtype=dtype)\n",
        "b = torch.randn((), device=device, dtype=dtype)\n",
        "c = torch.randn((), device=device, dtype=dtype)\n",
        "d = torch.randn((), device=device, dtype=dtype)\n",
        "## setting learning_rate\n",
        "learning_rate = 1e-6"
      ],
      "metadata": {
        "id": "jDrBAjL4TPSd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for t in range(2000):\n",
        "    # 순전파 단계: 예측값 y를 계산합니다\n",
        "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
        "\n",
        "    # 손실(loss)을 계산하고 출력합니다\n",
        "    loss = (y_pred - y).pow(2).sum().item()\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss)\n",
        "\n",
        "    # 손실에 따른 a, b, c, d의 변화도(gradient)를 계산하고 역전파합니다.\n",
        "    grad_y_pred = 2.0 * (y_pred - y)\n",
        "    grad_a = grad_y_pred.sum()\n",
        "    grad_b = (grad_y_pred * x).sum()\n",
        "    grad_c = (grad_y_pred * x ** 2).sum()\n",
        "    grad_d = (grad_y_pred * x ** 3).sum()\n",
        "\n",
        "    # renew the weight.\n",
        "    a -= learning_rate * grad_a\n",
        "    b -= learning_rate * grad_b\n",
        "    c -= learning_rate * grad_c\n",
        "    d -= learning_rate * grad_d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRvkSKspUHY5",
        "outputId": "11ddeb39-eb7d-4172-9d5b-8c793c29d431"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99 620.39697265625\n",
            "199 435.6003112792969\n",
            "299 306.8619689941406\n",
            "399 217.10464477539062\n",
            "499 154.47683715820312\n",
            "599 110.74593353271484\n",
            "699 80.18842315673828\n",
            "799 58.82151412963867\n",
            "899 43.87111282348633\n",
            "999 33.40376281738281\n",
            "1099 26.070842742919922\n",
            "1199 20.93084716796875\n",
            "1299 17.32600975036621\n",
            "1399 14.796545028686523\n",
            "1499 13.020750045776367\n",
            "1599 11.773505210876465\n",
            "1699 10.897109031677246\n",
            "1799 10.281021118164062\n",
            "1899 9.847761154174805\n",
            "1999 9.54296588897705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsrB4vBCTQHj",
        "outputId": "e9412018-bc16-40c6-c5a1-8a6e64d70cdd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result: y = 0.027516890317201614 + 0.8498680591583252 x + -0.004747121594846249 x^2 + -0.09235279262065887 x^3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pytorch nn module"
      ],
      "metadata": {
        "id": "Z6ZtSvnEVprX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import torch\n",
        "import math\n",
        "\n",
        "# 입력값과 출력값을 갖는 텐서들을 생성합니다.\n",
        "x = torch.linspace(-math.pi, math.pi, 2000)\n",
        "y = torch.sin(x)\n",
        "\n",
        "# 이 예제에서, 출력 y는 (x, x^2, x^3)의 선형 함수이므로, 선형 계층 신경망으로 간주할 수 있습니다.\n",
        "# (x, x^2, x^3)를 위한 텐서를 준비합니다.\n",
        "p = torch.tensor([1, 2, 3])\n",
        "xx = x.unsqueeze(-1).pow(p)"
      ],
      "metadata": {
        "id": "-ydLcScwVpcA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7h-VChIWIsq",
        "outputId": "83f32a29-cecd-44bb-a28d-7e946acf3169"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-3.1416, -3.1384, -3.1353,  ...,  3.1353,  3.1384,  3.1416])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.unsqueeze(-1) ## (1,2000)의 shae을 (2000,1)로 변환"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gS9MizMgWKIq",
        "outputId": "9f2de9a6-819a-4c28-845a-59a532c9d870"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-3.1416],\n",
              "        [-3.1384],\n",
              "        [-3.1353],\n",
              "        ...,\n",
              "        [ 3.1353],\n",
              "        [ 3.1384],\n",
              "        [ 3.1416]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p ##(1,3)의 shpae"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQtg4zAeW2Vu",
        "outputId": "7a42f485-4d12-4a42-c42c-ec4e47d69fa3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.unsqueeze(-1).pow(p) ##(2000,1) shpae에서 p는 (1,3)의 shape 이므로 브로드캐스(broadcast)적용되어 (2000,3)의 tensor shape로 변환"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAaIY9UUWWQL",
        "outputId": "9d8c738e-08f9-4cb9-c777-d5b75d39f818"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ -3.1416,   9.8696, -31.0063],\n",
              "        [ -3.1384,   9.8499, -30.9133],\n",
              "        [ -3.1353,   9.8301, -30.8205],\n",
              "        ...,\n",
              "        [  3.1353,   9.8301,  30.8205],\n",
              "        [  3.1384,   9.8499,  30.9133],\n",
              "        [  3.1416,   9.8696,  31.0063]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How to use nn module in *pytorch* "
      ],
      "metadata": {
        "id": "loelxXGKXHrG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# nn 패키지를 사용하여 모델을 순차적 계층(sequence of layers)으로 정의합니다.\n",
        "# nn.Sequential은 다른 Module을 포함하는 Module로, 포함되는 Module들을 순차적으로 적용하여 \n",
        "# 출력을 생성합니다. 각각의 Linear Module은 선형 함수(linear function)를 사용하여 입력으로부터\n",
        "# 출력을 계산하고, 내부 Tensor에 가중치와 편향을 저장\n",
        "\n",
        "# Flatten 계층은 선형 계층의 출력을 `y` 의 shape에 맞도록(match) 1D 텐서로 폅니다(flatten).\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(3, 1),\n",
        "    torch.nn.Flatten(0, 1)\n",
        ")"
      ],
      "metadata": {
        "id": "W-I3_A8AVpZR"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 평균 제곱 오차(MSE; Mean Squared Error)를 손실 함수로 사용하겠습니다.\n",
        "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
        "learning_rate = 1e-6"
      ],
      "metadata": {
        "id": "g-I5axKVVpWQ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for t in range(2000):\n",
        "    # 순전파 단계: x를 모델에 전달하여 예측값 y를 계산합니다. Module 객체는 __call__ 연산자를 \n",
        "    # 덮어써서(override) 함수처럼 호출할 수 있도록 합니다. 이렇게 함으로써 입력 데이터의 텐서를 Module에 전달하여\n",
        "    # 출력 데이터의 텐서를 생성\n",
        "    y_pred = model(xx)\n",
        "\n",
        "    # 손실을 계산하고 출력합니다. 예측한 y와 정답인 y를 갖는 텐서들을 전달하고,\n",
        "    # 손실 함수는 손실(loss)을 갖는 텐서를 반환 \n",
        "    loss = loss_fn(y_pred, y)\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    # 역전파 단계를 실행하기 전에 변화도(gradient)를 0으로 만듭니다.\n",
        "    model.zero_grad()\n",
        "\n",
        "    # 역전파 단계: 모델의 학습 가능한 모든 매개변수에 대해 손실의 변화도를 계산합니다.\n",
        "    # 내부적으로 각 Module의 매개변수는 requires_grad=True일 때 텐서에 저장되므로,\n",
        "    # 아래 호출은 모델의 모든 학습 가능한 매개변수의 변화도를 계산\n",
        "    loss.backward()\n",
        "\n",
        "    # 경사하강법을 사용하여 가중치를 갱신합니다.\n",
        "    # 각 매개변수는 텐서이므로, 이전에 했던 것처럼 변화도에 접근할 수 있습니다.\n",
        "    with torch.no_grad():\n",
        "        for param in model.parameters():\n",
        "            param -= learning_rate * param.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffsWE3oyVpTB",
        "outputId": "80e5cb71-2525-4da0-9429-9e3f912961cd"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99 147.04132080078125\n",
            "199 103.75110626220703\n",
            "299 74.092529296875\n",
            "399 53.749820709228516\n",
            "499 39.78099822998047\n",
            "599 30.17804527282715\n",
            "699 23.569080352783203\n",
            "799 19.015592575073242\n",
            "899 15.874866485595703\n",
            "999 13.70626449584961\n",
            "1099 12.20732307434082\n",
            "1199 11.170193672180176\n",
            "1299 10.451847076416016\n",
            "1399 9.953824043273926\n",
            "1499 9.60820484161377\n",
            "1599 9.368146896362305\n",
            "1699 9.201247215270996\n",
            "1799 9.085113525390625\n",
            "1899 9.00423812866211\n",
            "1999 8.947864532470703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list의 첫번째 항목에 접근하는 것처럼 `model` 의 첫번째 계층(layer)에 접근할 수 있습니다.\n",
        "linear_layer = model[0] ##model의 첫번째 계층 "
      ],
      "metadata": {
        "id": "oOgeix8KVpQL"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_layer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K88a55x0YuG0",
        "outputId": "578ffbfc-1e8f-4c7f-92d0-92261e8a5b30"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=3, out_features=1, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 선형 계층에서, 매개변수는 `weights` 와 `bias` 로 저장됩니다.\n",
        "print(f'Result: y = {linear_layer.bias.item()} + {linear_layer.weight[:, 0].item()} x + {linear_layer.weight[:, 1].item()} x^2 + {linear_layer.weight[:, 2].item()} x^3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DB5lLH7bVpNZ",
        "outputId": "950c4093-7b6f-4c1c-d8a4-b4e7cf0b8083"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result: y = 0.010934405028820038 + 0.8519801497459412 x + -0.0018863670993596315 x^2 + -0.09265322238206863 x^3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pytorch Optim"
      ],
      "metadata": {
        "id": "x4zG1LGbZ9cG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import torch\n",
        "import math\n",
        "\n",
        "# 입력값과 출력값을 갖는 텐서들을 생성합니다.\n",
        "x = torch.linspace(-math.pi, math.pi, 2000)\n",
        "y = torch.sin(x)\n",
        "\n",
        "# 입력 텐서 (x, x^2, x^3)를 준비합니다.\n",
        "p = torch.tensor([1, 2, 3])\n",
        "xx = x.unsqueeze(-1).pow(p)\n",
        "\n",
        "# nn 패키지를 사용하여 모델과 손실 함수를 정의합니다.\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(3, 1),\n",
        "    torch.nn.Flatten(0, 1)\n",
        ")\n",
        "loss_fn = torch.nn.MSELoss(reduction='sum')"
      ],
      "metadata": {
        "id": "b8neoHQcVpKX"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optim 패키지를 사용하여 모델의 가중치를 갱신할 optimizer를 정의합니다.\n",
        "# RMSprop을 사용하겠습니다; optim 패키지는 다른 다양한 최적화 알고리즘을 포함하고 있습니다.\n",
        "# RMSprop 생성자의 첫번째 인자는 어떤 텐서가 갱신되어야 하는지를 알려줍니다.\n",
        "learning_rate = 1e-3\n",
        "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
        "for t in range(2000):\n",
        "    # 순전파 단계: 모델에 x를 전달하여 예측값 y를 계산합니다.\n",
        "    y_pred = model(xx)\n",
        "\n",
        "    # 손실을 계산하고 출력합니다.\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    # 역전파 단계 전에, optimizer 객체를 사용하여 (모델의 학습 가능한 가중치인) 갱신할\n",
        "    # 변수들에 대한 모든 변화도(gradient)를 0으로 만듭니다. 이렇게 하는 이유는 기본적으로 \n",
        "    # .backward()를 호출할 때마다 변화도가 버퍼(buffer)에 (덮어쓰지 않고) 누적되기\n",
        "    # 때문입니다. 더 자세한 내용은 torch.autograd.backward에 대한 문서를 참조하세요.\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 역전파 단계: 모델의 매개변수들에 대한 손실의 변화도를 계산합니다.\n",
        "    loss.backward()\n",
        "\n",
        "    # optimizer의 step 함수를 호출하면 매개변수가 갱신됩니다.\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "linear_layer = model[0]\n",
        "print(f'Result: y = {linear_layer.bias.item()} + {linear_layer.weight[:, 0].item()} x + {linear_layer.weight[:, 1].item()} x^2 + {linear_layer.weight[:, 2].item()} x^3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lib5fNUCVpHf",
        "outputId": "3b4dd0a8-bb43-4d17-dc69-3e6c66d4a418"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99 4476.55029296875\n",
            "199 1775.3570556640625\n",
            "299 1332.427978515625\n",
            "399 1152.7113037109375\n",
            "499 969.0203247070312\n",
            "599 792.2801513671875\n",
            "699 633.6397705078125\n",
            "799 495.29986572265625\n",
            "899 376.5226135253906\n",
            "999 276.525146484375\n",
            "1099 194.5030975341797\n",
            "1199 129.5443878173828\n",
            "1299 80.58636474609375\n",
            "1399 46.41887664794922\n",
            "1499 25.021236419677734\n",
            "1599 13.944642066955566\n",
            "1699 9.83834457397461\n",
            "1799 9.020600318908691\n",
            "1899 8.902854919433594\n",
            "1999 8.889137268066406\n",
            "Result: y = -3.6392059143963706e-08 + 0.856989324092865 x + -3.583037511134535e-08 x^2 + -0.0928548276424408 x^3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch: 사용자 정의 nn.Module"
      ],
      "metadata": {
        "id": "GR8dt6GSajXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import torch\n",
        "import math\n",
        "\n",
        "class Polynomial3(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        생성자에서 4개의 매개변수를 생성(instantiate)하고, 멤버 변수로 지정합니다.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.a = torch.nn.Parameter(torch.randn(()))\n",
        "        self.b = torch.nn.Parameter(torch.randn(()))\n",
        "        self.c = torch.nn.Parameter(torch.randn(()))\n",
        "        self.d = torch.nn.Parameter(torch.randn(()))\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        순전파 함수에서는 입력 데이터의 텐서를 받고 출력 데이터의 텐서를 반환해야 합니다.\n",
        "        텐서들 간의 임의의 연산뿐만 아니라, 생성자에서 정의한 Module을 사용할 수 있습니다.\n",
        "        \"\"\"\n",
        "        return self.a + self.b * x + self.c * x ** 2 + self.d * x ** 3\n",
        "\n",
        "    def string(self):\n",
        "        \"\"\"\n",
        "        Python의 다른 클래스(class)처럼, PyTorch 모듈을 사용해서 사용자 정의 메소드를 정의할 수 있습니다.\n",
        "        \"\"\"\n",
        "        return f'y = {self.a.item()} + {self.b.item()} x + {self.c.item()} x^2 + {self.d.item()} x^3'\n"
      ],
      "metadata": {
        "id": "C7QpPaZHVpB3"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력값과 출력값을 갖는 텐서들을 생성합니다.\n",
        "x = torch.linspace(-math.pi, math.pi, 2000)\n",
        "y = torch.sin(x)\n",
        "\n",
        "# 위에서 정의한 클래스로 모델을 생성합니다.\n",
        "model = Polynomial3()\n",
        "\n",
        "# 손실 함수와 optimizer를 생성합니다. SGD 생성자에 model.paramaters()를 호출해주면\n",
        "# 모델의 멤버 학습 가능한 (torch.nn.Parameter로 정의된) 매개변수들이 포함됩니다.\n",
        "criterion = torch.nn.MSELoss(reduction='sum')\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-6)"
      ],
      "metadata": {
        "id": "IpCaJFYXVo4Y"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for t in range(2000):\n",
        "    # 순전파 단계: 모델에 x를 전달하여 예측값 y를 계산합니다.\n",
        "    y_pred = model(x)\n",
        "\n",
        "    # 손실을 계산하고 출력합니다.\n",
        "    loss = criterion(y_pred, y)\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss.item())\n",
        "    # 변화도를 0으로 만들고, 역전파 단계를 수행하고, 가중치를 갱신합니다.\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(f'Result: {model.string()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79cF-qLBa2dm",
        "outputId": "e4ace3f8-8eb5-4279-b37e-a10ce428fd5c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99 287.65771484375\n",
            "199 206.05972290039062\n",
            "299 148.34426879882812\n",
            "399 107.51943969726562\n",
            "499 78.64134979248047\n",
            "599 58.213356018066406\n",
            "699 43.7625617980957\n",
            "799 33.5397834777832\n",
            "899 26.307836532592773\n",
            "999 21.191612243652344\n",
            "1099 17.57209014892578\n",
            "1199 15.011359214782715\n",
            "1299 13.199676513671875\n",
            "1399 11.917917251586914\n",
            "1499 11.011055946350098\n",
            "1599 10.369440078735352\n",
            "1699 9.91547966003418\n",
            "1799 9.59428596496582\n",
            "1899 9.367027282714844\n",
            "1999 9.206233978271484\n",
            "Result: y = 0.020860688760876656 + 0.8559500575065613 x + -0.0035988122690469027 x^2 + -0.09321790933609009 x^3\n"
          ]
        }
      ]
    }
  ]
}