{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import Libraries","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import os\nimport glob\nimport random\nimport cv2\nfrom PIL import Image\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.data as data\nfrom torch.utils.data import DataLoader\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nfrom torchvision.utils import make_grid\nimport torchvision.transforms as tt\nimport albumentations as A\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2022-01-10T01:42:53.088969Z","iopub.execute_input":"2022-01-10T01:42:53.089328Z","iopub.status.idle":"2022-01-10T01:42:56.957999Z","shell.execute_reply.started":"2022-01-10T01:42:53.089223Z","shell.execute_reply":"2022-01-10T01:42:56.957118Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Using {} device\".format(device))","metadata":{"execution":{"iopub.status.busy":"2022-01-10T01:43:13.906621Z","iopub.execute_input":"2022-01-10T01:43:13.907118Z","iopub.status.idle":"2022-01-10T01:43:13.952018Z","shell.execute_reply.started":"2022-01-10T01:43:13.907080Z","shell.execute_reply":"2022-01-10T01:43:13.951305Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed = 0):\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    \nset_seed()","metadata":{"execution":{"iopub.status.busy":"2022-01-10T01:43:19.625851Z","iopub.execute_input":"2022-01-10T01:43:19.626541Z","iopub.status.idle":"2022-01-10T01:43:19.634991Z","shell.execute_reply.started":"2022-01-10T01:43:19.626502Z","shell.execute_reply":"2022-01-10T01:43:19.634234Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Load files path / Handling","metadata":{}},{"cell_type":"code","source":"ROOT_PATH = '../input/lgg-mri-segmentation/kaggle_3m/'\n\nmask_files = glob.glob(ROOT_PATH + '*/*_mask*')\nimage_files = [file.replace('_mask', '') for file in mask_files]","metadata":{"execution":{"iopub.status.busy":"2022-01-10T01:44:02.355967Z","iopub.execute_input":"2022-01-10T01:44:02.356226Z","iopub.status.idle":"2022-01-10T01:44:02.423431Z","shell.execute_reply.started":"2022-01-10T01:44:02.356196Z","shell.execute_reply":"2022-01-10T01:44:02.422659Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"mask_files[0] ## extract sample 1","metadata":{"execution":{"iopub.status.busy":"2022-01-10T01:44:27.395977Z","iopub.execute_input":"2022-01-10T01:44:27.396406Z","iopub.status.idle":"2022-01-10T01:44:27.405853Z","shell.execute_reply.started":"2022-01-10T01:44:27.396369Z","shell.execute_reply":"2022-01-10T01:44:27.405041Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def diagnosis(mask_path):\n    return 1 if np.max(cv2.imread(mask_path)) > 0 else 0","metadata":{"execution":{"iopub.status.busy":"2022-01-10T01:44:49.523178Z","iopub.execute_input":"2022-01-10T01:44:49.523734Z","iopub.status.idle":"2022-01-10T01:44:49.530276Z","shell.execute_reply.started":"2022-01-10T01:44:49.523697Z","shell.execute_reply":"2022-01-10T01:44:49.529506Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"files_df = pd.DataFrame({\"image_path\": image_files,\n                  \"mask_path\": mask_files,\n                  \"diagnosis\": [diagnosis(x) for x in mask_files]})\n\nfiles_df","metadata":{"execution":{"iopub.status.busy":"2022-01-10T01:44:56.774835Z","iopub.execute_input":"2022-01-10T01:44:56.775537Z","iopub.status.idle":"2022-01-10T01:45:00.432822Z","shell.execute_reply.started":"2022-01-10T01:44:56.775499Z","shell.execute_reply":"2022-01-10T01:45:00.432135Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Data distribution/ visaulization","metadata":{}},{"cell_type":"code","source":"ax = files_df['diagnosis'].value_counts().plot(kind='bar', stacked=True, figsize=(6,6), color=['skyblue', 'orange'])\nax.set_title('Data Distribution', fontsize=15)\nax.set_ylabel('Number of Images', fontsize=15)\nax.set_xticklabels(['No Tumor', 'Tumor'], fontsize=12, rotation=0)\nfor i, rows in enumerate(files_df['diagnosis'].value_counts().values):\n    ax.annotate(int(rows), xy=(i, rows+12), ha='center', fontweight='bold', fontsize=12)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T01:48:34.420069Z","iopub.execute_input":"2022-01-10T01:48:34.420336Z","iopub.status.idle":"2022-01-10T01:48:34.603790Z","shell.execute_reply.started":"2022-01-10T01:48:34.420306Z","shell.execute_reply":"2022-01-10T01:48:34.603080Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Train-Validation-Test split","metadata":{}},{"cell_type":"code","source":"train_df, val_df = train_test_split(files_df, stratify=files_df['diagnosis'], test_size=0.1, random_state=0)\ntrain_df = train_df.reset_index(drop=True)\nval_df = val_df.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T01:50:23.667313Z","iopub.execute_input":"2022-01-10T01:50:23.667851Z","iopub.status.idle":"2022-01-10T01:50:23.682115Z","shell.execute_reply.started":"2022-01-10T01:50:23.667814Z","shell.execute_reply":"2022-01-10T01:50:23.681465Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_df, test_df = train_test_split(train_df, stratify=train_df['diagnosis'], test_size=0.15, random_state=0)\ntrain_df = train_df.reset_index(drop=True)\ntest_df = test_df.reset_index(drop=True)\nprint(\"Train: {}\\nVal: {}\\nTest: {}\".format(train_df.shape, val_df.shape, test_df.shape))","metadata":{"execution":{"iopub.status.busy":"2022-01-10T01:50:33.615852Z","iopub.execute_input":"2022-01-10T01:50:33.616615Z","iopub.status.idle":"2022-01-10T01:50:33.629275Z","shell.execute_reply.started":"2022-01-10T01:50:33.616572Z","shell.execute_reply":"2022-01-10T01:50:33.628181Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Viewing the dataset","metadata":{}},{"cell_type":"code","source":"set_seed(0)\n\nimages, masks = [], []\ndf_positive = train_df[train_df['diagnosis']==1].sample(5).values","metadata":{"execution":{"iopub.status.busy":"2022-01-10T01:57:03.658136Z","iopub.execute_input":"2022-01-10T01:57:03.658713Z","iopub.status.idle":"2022-01-10T01:57:03.666341Z","shell.execute_reply.started":"2022-01-10T01:57:03.658676Z","shell.execute_reply":"2022-01-10T01:57:03.665569Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"for sample in df_positive:\n    img = cv2.imread(sample[0])\n    mask = cv2.imread(sample[1])\n    images.append(img)\n    masks.append(mask)\nimages = np.hstack(np.array(images))\nmasks = np.hstack(np.array(masks))\n\nfig = plt.figure(figsize=(15,10))\ngrid = ImageGrid(fig, 111, nrows_ncols=(3,1), axes_pad=0.4)\n\ngrid[0].imshow(images)\ngrid[0].set_title('Images', fontsize=15)\ngrid[0].axis('off')\ngrid[1].imshow(masks)\ngrid[1].set_title('Masks', fontsize=15)\ngrid[1].axis('off')\ngrid[2].imshow(images)\ngrid[2].imshow(masks, alpha=0.4)\ngrid[2].set_title('Brain MRI with mask', fontsize=15)\ngrid[2].axis('off')","metadata":{"execution":{"iopub.status.busy":"2022-01-10T01:57:04.000124Z","iopub.execute_input":"2022-01-10T01:57:04.000919Z","iopub.status.idle":"2022-01-10T01:57:04.699884Z","shell.execute_reply.started":"2022-01-10T01:57:04.000869Z","shell.execute_reply":"2022-01-10T01:57:04.699289Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## Converting to PyTorch dataset format","metadata":{}},{"cell_type":"code","source":"class BrainDataset(data.Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        image = cv2.imread(self.df.iloc[idx, 0])\n        image = np.array(image)/255.\n        mask = cv2.imread(self.df.iloc[idx, 1], 0)\n        mask = np.array(mask)/255.\n        \n        if self.transform is not None:\n            aug = self.transform(image=image, mask=mask)\n            image = aug['image']\n            mask = aug['mask']\n        \n        image = image.transpose((2,0,1))\n        image = torch.from_numpy(image).type(torch.float32)\n        image = tt.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))(image)\n        mask = np.expand_dims(mask, axis=-1).transpose((2,0,1))\n        mask = torch.from_numpy(mask).type(torch.float32)\n        \n        return image, mask","metadata":{"execution":{"iopub.status.busy":"2022-01-10T01:57:43.366582Z","iopub.execute_input":"2022-01-10T01:57:43.366846Z","iopub.status.idle":"2022-01-10T01:57:43.376781Z","shell.execute_reply.started":"2022-01-10T01:57:43.366816Z","shell.execute_reply":"2022-01-10T01:57:43.375849Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"### Augmentations","metadata":{}},{"cell_type":"code","source":"train_transform = A.Compose([\n    A.Resize(width=128, height=128, p=1.0),\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.5),\n    A.RandomRotate90(p=0.5),\n    A.ShiftScaleRotate(shift_limit=0.01, scale_limit=0.04, rotate_limit=0, p=0.25),\n])\n\nval_transform = A.Compose([\n    A.Resize(width=128, height=128, p=1.0),\n    A.HorizontalFlip(p=0.5),\n])\n\ntest_transform = A.Compose([\n    A.Resize(width=128, height=128, p=1.0)\n])","metadata":{"execution":{"iopub.status.busy":"2022-01-10T01:58:42.504833Z","iopub.execute_input":"2022-01-10T01:58:42.505543Z","iopub.status.idle":"2022-01-10T01:58:42.511330Z","shell.execute_reply.started":"2022-01-10T01:58:42.505505Z","shell.execute_reply":"2022-01-10T01:58:42.510567Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"set_seed(0) ##apply augmentation\ntrain_ds = BrainDataset(train_df, train_transform)\nval_ds = BrainDataset(val_df, val_transform)\ntest_ds = BrainDataset(test_df, test_transform)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T01:59:08.204683Z","iopub.execute_input":"2022-01-10T01:59:08.205295Z","iopub.status.idle":"2022-01-10T01:59:08.212413Z","shell.execute_reply.started":"2022-01-10T01:59:08.205250Z","shell.execute_reply":"2022-01-10T01:59:08.211444Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def dataset_info(dataset): \n    print(f'Size of dataset: {len(dataset)}')\n    index = random.randint(1, 40)\n    img, label = dataset[index]\n    print(f'Sample-{index} Image size: {img.shape}, Mask: {label.shape}\\n')","metadata":{"execution":{"iopub.status.busy":"2022-01-10T01:59:18.367338Z","iopub.execute_input":"2022-01-10T01:59:18.367784Z","iopub.status.idle":"2022-01-10T01:59:18.372819Z","shell.execute_reply.started":"2022-01-10T01:59:18.367747Z","shell.execute_reply":"2022-01-10T01:59:18.372002Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"print('Train dataset:')\ndataset_info(train_ds)\nprint('Validation dataset:')\ndataset_info(val_ds)\nprint('Test dataset:')\ndataset_info(test_ds)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T01:59:23.485099Z","iopub.execute_input":"2022-01-10T01:59:23.485376Z","iopub.status.idle":"2022-01-10T01:59:23.598700Z","shell.execute_reply.started":"2022-01-10T01:59:23.485344Z","shell.execute_reply":"2022-01-10T01:59:23.597927Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"## Creating Dataloaders","metadata":{}},{"cell_type":"code","source":"batch_size = 64\n\nset_seed(0)\ntrain_dl = DataLoader(train_ds, \n                      batch_size, \n                      shuffle=True, \n                      num_workers=2,  \n                      pin_memory=True)  \n\nset_seed(0)\nval_dl = DataLoader(val_ds, \n                    batch_size,   \n                    num_workers=2, \n                    pin_memory=True)\n\ntest_dl = DataLoader(val_ds, \n                    1,   \n                    num_workers=2, \n                    pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T02:00:11.626836Z","iopub.execute_input":"2022-01-10T02:00:11.627086Z","iopub.status.idle":"2022-01-10T02:00:11.635685Z","shell.execute_reply.started":"2022-01-10T02:00:11.627058Z","shell.execute_reply":"2022-01-10T02:00:11.634902Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"images, masks = next(iter(train_dl))\nprint(images.shape)\nprint(masks.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T02:00:19.131817Z","iopub.execute_input":"2022-01-10T02:00:19.132073Z","iopub.status.idle":"2022-01-10T02:00:23.629148Z","shell.execute_reply.started":"2022-01-10T02:00:19.132044Z","shell.execute_reply":"2022-01-10T02:00:23.627497Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"### Viewing samples from a batch","metadata":{}},{"cell_type":"code","source":"def denormalize(images):\n    means = torch.tensor([0.485, 0.456, 0.406]).reshape(1, 3, 1, 1)\n    stds = torch.tensor([0.229, 0.224, 0.225]).reshape(1, 3, 1, 1)\n    return images * stds + means\n\ndef show_batch(dl):\n    for images, masks in dl:\n        fig1, ax1 = plt.subplots(figsize=(24, 24))\n        ax1.set_xticks([]); ax1.set_yticks([])\n        denorm_images = denormalize(images)\n        ax1.imshow(make_grid(denorm_images[:13], nrow=13).permute(1, 2, 0).clamp(0,1))\n        \n        fig2, ax2 = plt.subplots(figsize=(24, 24))\n        ax2.set_xticks([]); ax2.set_yticks([])\n        ax2.imshow(make_grid(masks[:13], nrow=13).permute(1, 2, 0).clamp(0,1))\n        break\n        \nshow_batch(train_dl)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T02:00:56.379917Z","iopub.execute_input":"2022-01-10T02:00:56.380191Z","iopub.status.idle":"2022-01-10T02:00:58.442750Z","shell.execute_reply.started":"2022-01-10T02:00:56.380157Z","shell.execute_reply":"2022-01-10T02:00:58.441884Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"## Defining the UNET model","metadata":{}},{"cell_type":"code","source":"class DoubleConv(nn.Module):\n    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n    def __init__(self, in_channels, out_channels, mid_channels=None):\n        super().__init__()\n        if not mid_channels:\n            mid_channels = out_channels\n        self.double_conv = nn.Sequential(\n            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(mid_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True))\n    def forward(self, x):\n        return self.double_conv(x)\n    \nclass Down(nn.Module):\n    \"\"\"Downscaling with maxpool then double conv\"\"\"\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.maxpool_conv = nn.Sequential(\n            nn.MaxPool2d(2),\n            DoubleConv(in_channels, out_channels))\n    def forward(self, x):\n        return self.maxpool_conv(x)\n    \nclass Up(nn.Module):\n    \"\"\"Upscaling then double conv\"\"\"\n    def __init__(self, in_channels, out_channels, bilinear=True):\n        super().__init__()\n        if bilinear:\n            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n            self.conv = DoubleConv(in_channels, out_channels, in_channels//2)\n        else:\n            self.up = nn.ConvTranspose2d(in_channels, in_channels//2, kernel_size=2, stride=2)\n            self.conv = DoubleConv(in_channels, out_channels)\n    def forward(self, x1, x2):\n        x1 = self.up(x1)\n        diffY = x2.size()[2] - x1.size()[2]\n        diffX = x2.size()[3] - x1.size()[3]\n        \n        x1 = F.pad(x1, [diffX//2, diffX-diffX//2,\n                        diffY//2, diffY-diffY//2])\n        x = torch.cat([x2, x1], dim=1)\n        return self.conv(x)\n\nclass OutConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(OutConv, self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=1),\n            nn.Sigmoid())\n    def forward(self, x):\n        return self.conv(x)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T02:01:15.602586Z","iopub.execute_input":"2022-01-10T02:01:15.602851Z","iopub.status.idle":"2022-01-10T02:01:15.619635Z","shell.execute_reply.started":"2022-01-10T02:01:15.602820Z","shell.execute_reply":"2022-01-10T02:01:15.618848Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"class UNet(nn.Module):\n    def __init__(self, n_channels, n_classes, bilinear=True):\n        super(UNet, self).__init__()\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.bilinear = bilinear\n        \n        self.inc = DoubleConv(n_channels, 64)\n        self.down1 = Down(64, 128)\n        self.down2 = Down(128, 256)\n        self.down3 = Down(256, 512)\n        factor = 2 if bilinear else 1\n        self.down4 = Down(512, 1024//factor)\n        self.up1 = Up(1024, 512//factor, bilinear)\n        self.up2 = Up(512, 256//factor, bilinear)        \n        self.up3 = Up(256, 128//factor, bilinear)        \n        self.up4 = Up(128, 64, bilinear)        \n        self.outc = OutConv(64, n_classes)\n    \n    def forward(self, x):\n        x1 = self.inc(x)\n        x2 = self.down1(x1)\n        x3 = self.down2(x2)\n        x4 = self.down3(x3)\n        x5 = self.down4(x4)\n        x = self.up1(x5, x4)\n        x = self.up2(x, x3)\n        x = self.up3(x, x2)\n        x = self.up4(x, x1)\n        logits = self.outc(x)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2022-01-10T02:01:20.907710Z","iopub.execute_input":"2022-01-10T02:01:20.907967Z","iopub.status.idle":"2022-01-10T02:01:20.920255Z","shell.execute_reply.started":"2022-01-10T02:01:20.907935Z","shell.execute_reply":"2022-01-10T02:01:20.919558Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"model = UNet(3, 1).to(device)\nout = model(torch.randn(1, 3, 128, 128).to(device))\nprint(out.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T02:01:29.097561Z","iopub.execute_input":"2022-01-10T02:01:29.097816Z","iopub.status.idle":"2022-01-10T02:01:34.259737Z","shell.execute_reply.started":"2022-01-10T02:01:29.097787Z","shell.execute_reply":"2022-01-10T02:01:34.258942Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"## Metric & Loss fn","metadata":{}},{"cell_type":"code","source":"def dice_coef_metric(pred, label):\n    intersection = 2.0 * (pred * label).sum()\n    union = pred.sum() + label.sum()\n    if pred.sum() == 0 and label.sum() == 0:\n        return 1.\n    return intersection / union\n\ndef dice_coef_loss(pred, label):\n    smooth = 1.0\n    intersection = 2.0 * (pred * label).sum() + smooth\n    union = pred.sum() + label.sum() + smooth\n    return 1 - (intersection / union)\n\ndef bce_dice_loss(pred, label):\n    dice_loss = dice_coef_loss(pred, label)\n    bce_loss = nn.BCELoss()(pred, label)\n    return dice_loss + bce_loss","metadata":{"execution":{"iopub.status.busy":"2022-01-10T02:01:45.114721Z","iopub.execute_input":"2022-01-10T02:01:45.115021Z","iopub.status.idle":"2022-01-10T02:01:45.122813Z","shell.execute_reply.started":"2022-01-10T02:01:45.114987Z","shell.execute_reply":"2022-01-10T02:01:45.122082Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"## Training ","metadata":{}},{"cell_type":"markdown","source":"### Train Loop","metadata":{}},{"cell_type":"code","source":"def train_loop(model, loader, loss_func):\n    model.train()\n    train_losses = []\n    train_dices = []\n    \n#     for i, (image, mask) in enumerate(tqdm(loader)):\n    for i, (image, mask) in enumerate(loader):\n        image = image.to(device)\n        mask = mask.to(device)\n        outputs = model(image)\n        out_cut = np.copy(outputs.data.cpu().numpy())\n        out_cut[np.nonzero(out_cut < 0.5)] = 0.0\n        out_cut[np.nonzero(out_cut >= 0.5)] = 1.0            \n\n        dice = dice_coef_metric(out_cut, mask.data.cpu().numpy())\n        loss = loss_func(outputs, mask)\n        train_losses.append(loss.item())\n        train_dices.append(dice)\n\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        \n    return train_dices, train_losses","metadata":{"execution":{"iopub.status.busy":"2022-01-10T02:01:56.199176Z","iopub.execute_input":"2022-01-10T02:01:56.199862Z","iopub.status.idle":"2022-01-10T02:01:56.207744Z","shell.execute_reply.started":"2022-01-10T02:01:56.199826Z","shell.execute_reply":"2022-01-10T02:01:56.206919Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"### Validation loop","metadata":{}},{"cell_type":"code","source":"def eval_loop(model, loader, loss_func, training=True):\n    model.eval()\n    val_loss = 0\n    val_dice = 0\n    with torch.no_grad():\n        for step, (image, mask) in enumerate(loader):\n            image = image.to(device)\n            mask = mask.to(device)\n    \n            outputs = model(image)\n            loss = loss_func(outputs, mask)\n            \n            out_cut = np.copy(outputs.data.cpu().numpy())\n            out_cut[np.nonzero(out_cut < 0.5)] = 0.0\n            out_cut[np.nonzero(out_cut >= 0.5)] = 1.0\n            dice = dice_coef_metric(out_cut, mask.data.cpu().numpy())\n            \n            val_loss += loss\n            val_dice += dice\n        \n        val_mean_dice = val_dice / step\n        val_mean_loss = val_loss / step\n        \n        if training:\n            scheduler.step(val_mean_dice)\n        \n    return val_mean_dice, val_mean_loss","metadata":{"execution":{"iopub.status.busy":"2022-01-10T02:02:01.969281Z","iopub.execute_input":"2022-01-10T02:02:01.969937Z","iopub.status.idle":"2022-01-10T02:02:01.977752Z","shell.execute_reply.started":"2022-01-10T02:02:01.969900Z","shell.execute_reply":"2022-01-10T02:02:01.976932Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"### Train Function","metadata":{}},{"cell_type":"code","source":"def train_model(train_loader, val_loader, loss_func, optimizer, scheduler, num_epochs):\n    train_loss_history = []\n    train_dice_history = []\n    val_loss_history = []\n    val_dice_history = []\n    \n    for epoch in range(num_epochs):\n        train_dices, train_losses = train_loop(model, train_loader, loss_func)\n        train_mean_dice = np.array(train_dices).mean()\n        train_mean_loss = np.array(train_losses).mean()\n        val_mean_dice, val_mean_loss = eval_loop(model, val_loader, loss_func)\n        \n        train_loss_history.append(np.array(train_losses).mean())\n        train_dice_history.append(np.array(train_dices).mean())\n        val_loss_history.append(val_mean_loss)\n        val_dice_history.append(val_mean_dice)\n        \n        print('Epoch: {}/{} |  Train Loss: {:.3f}, Val Loss: {:.3f}, Train DICE: {:.3f}, Val DICE: {:.3f}'.format(epoch+1, num_epochs,\n                                                                                                                 train_mean_loss,\n                                                                                                                 val_mean_loss,\n                                                                                                                 train_mean_dice,\n                                                                                                                 val_mean_dice))\n        \n\n    return train_loss_history, train_dice_history, val_loss_history, val_dice_history","metadata":{"execution":{"iopub.status.busy":"2022-01-10T02:02:29.838343Z","iopub.execute_input":"2022-01-10T02:02:29.839091Z","iopub.status.idle":"2022-01-10T02:02:29.847380Z","shell.execute_reply.started":"2022-01-10T02:02:29.839049Z","shell.execute_reply":"2022-01-10T02:02:29.846562Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"### Hyperparameters","metadata":{}},{"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=3)\nnum_epochs = 30","metadata":{"execution":{"iopub.status.busy":"2022-01-10T02:03:53.415020Z","iopub.execute_input":"2022-01-10T02:03:53.415297Z","iopub.status.idle":"2022-01-10T02:03:53.422857Z","shell.execute_reply.started":"2022-01-10T02:03:53.415265Z","shell.execute_reply":"2022-01-10T02:03:53.422204Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"%%time\ntrain_loss_history, train_dice_history, val_loss_history, val_dice_history = train_model(train_dl, val_dl, bce_dice_loss, optimizer, scheduler, num_epochs)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T02:03:56.015101Z","iopub.execute_input":"2022-01-10T02:03:56.015873Z","iopub.status.idle":"2022-01-10T02:22:26.238846Z","shell.execute_reply.started":"2022-01-10T02:03:56.015833Z","shell.execute_reply":"2022-01-10T02:22:26.237946Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"## DICE Score History","metadata":{}},{"cell_type":"code","source":"def plot_dice_history(model_name, train_dice_history, val_dice_history, num_epochs):\n    \n    x = np.arange(num_epochs)\n    fig = plt.figure(figsize=(10, 6))\n    plt.plot(x, train_dice_history, label='Train DICE', lw=3, c=\"green\")\n    plt.plot(x, val_dice_history, label='Validation DICE', lw=3, c=\"skyblue\")\n\n    plt.title(f\"{model_name}\", fontsize=15)\n    plt.legend(fontsize=12)\n    plt.xlabel(\"Epoch\", fontsize=10)\n    plt.ylabel(\"DICE Score\", fontsize=10)\n\n    plt.show()\n    \nplot_dice_history('UNET-model', train_dice_history, val_dice_history, num_epochs)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T02:34:20.910668Z","iopub.execute_input":"2022-01-10T02:34:20.910995Z","iopub.status.idle":"2022-01-10T02:34:21.197630Z","shell.execute_reply.started":"2022-01-10T02:34:20.910959Z","shell.execute_reply":"2022-01-10T02:34:21.196939Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"## Loss History","metadata":{}},{"cell_type":"code","source":"def plot_loss_history(model_name, train_loss_history, val_loss_history, num_epochs):\n    \n    x = np.arange(num_epochs)\n    fig = plt.figure(figsize=(10, 6))\n    plt.plot(x, train_loss_history, label='Train Loss', lw=3, c=\"green\")\n    plt.plot(x, val_loss_history, label='Validation Loss', lw=3, c=\"skyblue\")\n\n    plt.title(f\"{model_name}\", fontsize=15)\n    plt.legend(fontsize=12)\n    plt.xlabel(\"Epoch\", fontsize=10)\n    plt.ylabel(\"Loss\", fontsize=10)\n\n    plt.show()\n    \nplot_loss_history('UNET', train_loss_history, val_loss_history, num_epochs)","metadata":{"execution":{"iopub.status.busy":"2022-01-10T02:34:58.370123Z","iopub.execute_input":"2022-01-10T02:34:58.370812Z","iopub.status.idle":"2022-01-10T02:34:58.584787Z","shell.execute_reply.started":"2022-01-10T02:34:58.370775Z","shell.execute_reply":"2022-01-10T02:34:58.584100Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"## Prediction on Test set","metadata":{}},{"cell_type":"code","source":"%%time\ntest_dice, test_loss = eval_loop(model, test_dl, bce_dice_loss, training=False)\nprint(\"Mean IoU/DICE: {:.3f}%, Loss: {:.3f}\".format((100*test_dice), test_loss))","metadata":{"execution":{"iopub.status.busy":"2022-01-10T02:35:04.663058Z","iopub.execute_input":"2022-01-10T02:35:04.663329Z","iopub.status.idle":"2022-01-10T02:35:10.347400Z","shell.execute_reply.started":"2022-01-10T02:35:04.663300Z","shell.execute_reply":"2022-01-10T02:35:10.346527Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"test_sample = test_df[test_df[\"diagnosis\"] == 1].sample(7).values[0]\nimage = cv2.resize(cv2.imread(test_sample[0]), (128, 128))\nmask = cv2.resize(cv2.imread(test_sample[1]), (128, 128))","metadata":{"execution":{"iopub.status.busy":"2022-01-10T02:35:55.876195Z","iopub.execute_input":"2022-01-10T02:35:55.876806Z","iopub.status.idle":"2022-01-10T02:35:55.900100Z","shell.execute_reply.started":"2022-01-10T02:35:55.876769Z","shell.execute_reply":"2022-01-10T02:35:55.899447Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"test_sample","metadata":{"execution":{"iopub.status.busy":"2022-01-10T02:36:01.491722Z","iopub.execute_input":"2022-01-10T02:36:01.492341Z","iopub.status.idle":"2022-01-10T02:36:01.498174Z","shell.execute_reply.started":"2022-01-10T02:36:01.492298Z","shell.execute_reply":"2022-01-10T02:36:01.497350Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"# pred\npred = torch.tensor(image.astype(np.float32) / 255.).unsqueeze(0).permute(0,3,1,2)\npred = tt.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))(pred)\npred = model(pred.to(device))\npred = pred.detach().cpu().numpy()[0,0,:,:]\n\npred_t = np.copy(pred)\npred_t[np.nonzero(pred_t < 0.3)] = 0.0\npred_t[np.nonzero(pred_t >= 0.3)] = 255.\npred_t = pred_t.astype(\"uint8\")","metadata":{"execution":{"iopub.status.busy":"2022-01-10T02:36:26.412352Z","iopub.execute_input":"2022-01-10T02:36:26.412983Z","iopub.status.idle":"2022-01-10T02:36:26.441741Z","shell.execute_reply.started":"2022-01-10T02:36:26.412946Z","shell.execute_reply":"2022-01-10T02:36:26.441058Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"# plot\nfig, ax = plt.subplots(nrows=2,  ncols=2, figsize=(10, 10))\n\nax[0, 0].imshow(image)\nax[0, 0].set_title(\"image\")\nax[0, 1].imshow(mask)\nax[0, 1].set_title(\"mask\")\nax[1, 0].imshow(pred)\nax[1, 0].set_title(\"prediction\")\nax[1, 1].imshow(pred_t)\nax[1, 1].set_title(\"prediction with threshold\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-10T02:36:33.177223Z","iopub.execute_input":"2022-01-10T02:36:33.177818Z","iopub.status.idle":"2022-01-10T02:36:33.686723Z","shell.execute_reply.started":"2022-01-10T02:36:33.177781Z","shell.execute_reply":"2022-01-10T02:36:33.686071Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":"## Saving the Model","metadata":{}},{"cell_type":"code","source":"torch.save(model.state_dict(), 'brain-mri-unet.pth')","metadata":{"execution":{"iopub.status.busy":"2022-01-10T02:36:42.156400Z","iopub.execute_input":"2022-01-10T02:36:42.156655Z","iopub.status.idle":"2022-01-10T02:36:42.470842Z","shell.execute_reply.started":"2022-01-10T02:36:42.156627Z","shell.execute_reply":"2022-01-10T02:36:42.470127Z"},"trusted":true},"execution_count":58,"outputs":[]}]}